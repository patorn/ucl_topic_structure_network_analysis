{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import igraph as ig\n",
    "import lda\n",
    "import os\n",
    "import pdb\n",
    "import nltk\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from os import makedirs\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = join('tmp', 'parsed')\n",
    "OUTPUT_DIR = join('tmp')\n",
    "makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary...\n",
      "9086\n"
     ]
    }
   ],
   "source": [
    "print(\"Building vocabulary...\")\n",
    "\n",
    "tokens = []\n",
    "docs = {}\n",
    "for fname in os.listdir(INPUT_DIR):\n",
    "    if fname != '.DS_Store':\n",
    "        with open(join(INPUT_DIR, fname), 'r') as f:\n",
    "            doc = json.load(f)\n",
    "            docs[doc['id']] = doc\n",
    "            text = doc['body']\n",
    "            table = str.maketrans({key: None for key in string.punctuation})\n",
    "            tokens.append((doc['id'], text.lower().translate(table)))\n",
    "\n",
    "token_keys = [x[0] for x in tokens]\n",
    "token_values = [x[1] for x in tokens]\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the graph from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TF-IDF\n",
      "(9086, 141273)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"Processing TF-IDF\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "X = vectorizer.fit_transform(token_values)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9086\n"
     ]
    }
   ],
   "source": [
    "g = ig.Graph()\n",
    "for i, key in enumerate(token_keys):\n",
    "    g.add_vertices(key)\n",
    "    \n",
    "print(g.vcount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82555396\n"
     ]
    }
   ],
   "source": [
    "g.delete_edges(g.es)\n",
    "edges = []\n",
    "for i, key in enumerate(token_keys):\n",
    "    print('{0}\\r'.format(i/len(token_keys)))\n",
    "    clear_output(wait=True)\n",
    "    for i_2, key_2 in enumerate(token_keys):\n",
    "        edges.append((key, key_2))\n",
    "            \n",
    "g.add_edges(edges)  \n",
    "edges = [] \n",
    "print(g.ecount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82555396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count = 0\n",
    "weights = []\n",
    "for i, key in enumerate(token_keys):\n",
    "    similarities = cosine_similarity(X[i], X)[0]\n",
    "    print('{0}\\r'.format(i/len(token_keys)))\n",
    "    clear_output(wait=True)\n",
    "    for i_2, key_2 in enumerate(token_keys):            \n",
    "        g.es[count][\"weight\"] = similarities[i_2]\n",
    "        count += 1\n",
    "\n",
    "print(g.ecount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove duplicated and self-loop edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41273155\n"
     ]
    }
   ],
   "source": [
    "g.simplify(multiple=True, loops=True, combine_edges=\"max\")\n",
    "print(g.ecount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027366185195034684"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.es[1]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g.write_gml('tmp/igraph.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmp/igraph_01.gml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-6f3c3981e8fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRead_GML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp/igraph_01.gml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmp/igraph_01.gml'"
     ]
    }
   ],
   "source": [
    "g = ig.Graph.Read_GML('tmp/igraph.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.es[1].tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "igraph.Vertex(<igraph.Graph object at 0x10e1f0d68>, 0, {'name': '2016-05-01-1'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.vs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_g = g.es.select(weight_ge=0).subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes 9086\n",
      "Edges 41273155\n",
      "AD 9085.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Nodes {}\".format(sub_g.vcount()))\n",
    "print(\"Edges {}\".format(sub_g.ecount()))\n",
    "# print(\"Diameter {}\".format(sub_g.diameter()))\n",
    "# print(\"LCC {}\".format(sub_g.clusters().giant().vcount()))\n",
    "# print(\"APL {}\".format(sub_g.average_path_length()))\n",
    "print(\"AD {}\".format(sum(sub_g.degree())/len(sub_g.degree())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1734)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_g.es()[0].tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igraph.Vertex(<igraph.Graph object at 0x10e1f0c78>, 0, {'name': '2016-05-01-122'})\n",
      "igraph.Vertex(<igraph.Graph object at 0x10e1f0c78>, 3, {'name': '2016-05-01-81'})\n"
     ]
    }
   ],
   "source": [
    "print(sub_g.vs[1])\n",
    "print(sub_g.vs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_g.write_gml('tmp/subgraph_01.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = ig.Graph.Read_GML('tmp/subgraph_01.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sg = g.es.select(weight_ge=0.2).subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# community = sg.community_infomap(edge_weights='weight')\n",
    "community = sg.community_multilevel(weights='weight')\n",
    "# community = sg.community_leading_eigenvector(weights='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "print(len(community.giant().vs()))\n",
    "print(max(community.membership))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(max(community.membership)):\n",
    "    for v in community.subgraph(i).vs():\n",
    "        print(\"Topic:{} File:{} Title:{}\".format(i, v['name'], docs[v['name']]['webTitle']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9086, 141273)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "X = vectorizer.fit_transform(token_values)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import matutils\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO \n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "%time model = LdaModel(matutils.Sparse2Corpus(X), num_topics=226, passes=50, id2word=dict([(i, s) for i, s in enumerate(vocab)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x10ff71e10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO \n",
    "\n",
    "model = lda.LDA(n_topics=226, n_iter=500, random_state=1)\n",
    "model.fit(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-62315246.82184576,\n",
       " -41876225.91660596,\n",
       " -39445246.49574409,\n",
       " -38541915.86386203,\n",
       " -38055713.18078848,\n",
       " -37751968.54957015,\n",
       " -37539842.882761106,\n",
       " -37384775.09410583,\n",
       " -37267310.24872986,\n",
       " -37177068.978081815,\n",
       " -37106785.53718555,\n",
       " -37038307.50484783,\n",
       " -36999428.71756243,\n",
       " -36952980.10411127,\n",
       " -36913235.96321809,\n",
       " -36881035.44178128,\n",
       " -36850973.83775497,\n",
       " -36829097.432930805,\n",
       " -36802845.03211314,\n",
       " -36784860.64174221,\n",
       " -36769968.29460513,\n",
       " -36747377.910839446,\n",
       " -36739656.531647734,\n",
       " -36723341.92872516,\n",
       " -36709627.093720585,\n",
       " -36693643.63736573,\n",
       " -36684448.38815882,\n",
       " -36675038.16955687,\n",
       " -36666628.57038627,\n",
       " -36656209.678821094,\n",
       " -36649861.68358176,\n",
       " -36645132.77845753,\n",
       " -36629221.07325693,\n",
       " -36631857.58642031,\n",
       " -36618503.877287865,\n",
       " -36605720.26917494,\n",
       " -36605773.08857173,\n",
       " -36605324.48081115,\n",
       " -36587709.57708163,\n",
       " -36584063.27008106,\n",
       " -36575889.01301607,\n",
       " -36572751.49003264,\n",
       " -36566194.53408205,\n",
       " -36563200.21564513,\n",
       " -36561874.521596454,\n",
       " -36547381.94235644,\n",
       " -36546164.56168147,\n",
       " -36547932.60788506,\n",
       " -36546128.39401351,\n",
       " -36534953.023006074]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loglikelihoods_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open('tmp/lda.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = pickle.load(open('tmp/lda.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(doc_topic): <class 'numpy.ndarray'>\n",
      "shape: (9086, 226)\n"
     ]
    }
   ],
   "source": [
    "doc_topic = model.doc_topic_\n",
    "print(\"type(doc_topic): {}\".format(type(doc_topic)))\n",
    "print(\"shape: {}\".format(doc_topic.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in range(len(doc_topic)):\n",
    "    topic_most_pr = doc_topic[n].argmax()\n",
    "    docs[token_keys[n]]['topic_most_pr'] = topic_most_pr\n",
    "\n",
    "sorted_items = sorted(docs.items(), key=lambda x: x[1]['topic_most_pr'])\n",
    "\n",
    "for item in sorted_items:\n",
    "    print(\"Topic:{} File:{} Title:{}...\".format(item[1]['topic_most_pr'], item[0], item[1]['webTitle'][:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two similar groups from two approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
